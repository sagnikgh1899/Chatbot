{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The heuristic limits of an incoming actual value are calculated based on historical data\n",
    "2. It represents expected normal data boundaries or behaviours. If an actual value is outside of the limits, then it is categorized as an anomaly. \n",
    "3. Given a sequece of values X as a time series we can calculate limit by 2 ways:\n",
    "4. limit(X) = median(X) (+-) 3 * median(|X - median(X)|)\n",
    "5. w = Set w (say 10) (DONE)\n",
    "6. X_t = x_t-10, ..., x_t, ... , x_t+10  --> Historical Data (basically considering 2w points) ?? (DONE)\n",
    "7. Divide X_t into 2 parts: (values less than median[X1]) and (values greater than or equal to median[X2]) (DONE)\n",
    "8. Upper = limit(X1_t) (DONE)\n",
    "9. Lower = limit(X2_t) (DONE)\n",
    "10. Anomaly Score (s) = (x - Upper/Lower) / (|x - median(X)|) --> is X the entire dataset or the historical data?? Considering X as the historical data!!\n",
    "11. S = set of anomaly scores\n",
    "12. Calculate the anomaly probability \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of all variables\n",
    "w --> window (int)\n",
    "num_of_points_considered (int)\n",
    "X_t --> Stores historical data (list)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the values\n",
    "w = int(input(\"Enter the window size\\n\"))\n",
    "name_of_file = str(input(\"\\nEnter the Filepath\\n\"))\n",
    "choice = int(input(\"\\nEnter choice of column\\n\"))\n",
    "num_of_points_considered = 0\n",
    "# data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Functions \n",
    "def divide_into_halves(X_t): # True for upper and False for lower\n",
    "    lower_half = []\n",
    "    upper_half = []\n",
    "    median_of_X_t = np.median(X_t)\n",
    "    # print(\"\\nMedian =\", np.median(X_t))\n",
    "    for ele in X_t:                                            # O(len X_t)\n",
    "        if ele < median_of_X_t:\n",
    "            lower_half.append(ele)\n",
    "        else:\n",
    "            upper_half.append(ele)\n",
    "    \n",
    "    # upper_limit = limit(upper_half, True)\n",
    "    # lower_limit = limit(lower_half, False)\n",
    "    # print(\"\\n\")\n",
    "    # print(lower_half)\n",
    "    # print(\"LL =\", lower_limit)\n",
    "    # print(upper_half)\n",
    "    # print(\"UL =\", upper_limit)\n",
    "    return lower_half, upper_half\n",
    "    \n",
    "    \n",
    "    \n",
    "def limit(X, boolean):\n",
    "    temp = []\n",
    "    for ele in X:                                               # O(len X_t)\n",
    "        temp.append(abs(X - np.median(X))) \n",
    "    return np.median(X) + 3 * np.median(temp) if boolean == True else np.median(X) - 3 * np.median(temp)\n",
    "\n",
    "\n",
    "\n",
    "def Anomaly_Score(X_t, upper, lower):\n",
    "    median = np.median(X_t)\n",
    "    # print(\"Median \", median)\n",
    "    anomaly_score = []\n",
    "    for x in X_t:                                               # O(len X_t)\n",
    "        s = (x - upper/lower) / (abs(x - median))\n",
    "        anomaly_score.append(s)\n",
    "    return anomaly_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def HLBOD(name_of_file, w, num_of_points_considered): # T/S : O(n*w) / O(n)\n",
    "    data = []                                                        # O(n space)\n",
    "    count2 = 0\n",
    "    whole_dataset = np.genfromtxt(name_of_file, delimiter=',',dtype=None, encoding=None, skip_header=1)\n",
    "    for ele in whole_dataset:                                        # O(n)\n",
    "        data.append(ele[choice])\n",
    "        count2 += 1\n",
    "        if count2 == 6000:\n",
    "            break\n",
    "    print(len(data))\n",
    "    # print(data)\n",
    "    anomaly_score = []\n",
    "    count = 0\n",
    "    while num_of_points_considered < len(data):                      # O(n * w)\n",
    "        remaining_points = 0\n",
    "        X_t = []\n",
    "        while remaining_points < 2*w:                                # O(w)\n",
    "            if num_of_points_considered + remaining_points == len(data):\n",
    "                num_of_points_considered = len(data)\n",
    "                break\n",
    "            X_t.append(data[num_of_points_considered + remaining_points])\n",
    "            remaining_points += 1\n",
    "\n",
    "        # divide_into_halves(X_t)                             \n",
    "        # print(\"\\n\", X_t)\n",
    "        print(\"Len of X_t = \", len(X_t))\n",
    "        lower_half, upper_half = divide_into_halves(X_t)             # O(w)\n",
    "        upper_limit = limit(upper_half, True)                        # O(w)\n",
    "        lower_limit = limit(lower_half, False)                       # O(w)\n",
    "        # anomaly_score = []\n",
    "        temp2 = []\n",
    "        temp2 = Anomaly_Score(X_t, upper_limit, lower_limit)         # O(w)\n",
    "        for ele in temp2:                                            # O(w)\n",
    "            if len(set(anomaly_score)) < 2:\n",
    "                anomaly_score.append(ele)\n",
    "            else:\n",
    "                anomaly_score.append((ele - min(temp2)) / (max(temp2) - min(temp2)))\n",
    "        #print(anomaly_score)\n",
    "        count += 1\n",
    "        num_of_points_considered += 2*w\n",
    "        print(\"Count = \",count)\n",
    "    return anomaly_score, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anomaly_score, data = HLBOD(name_of_file, w, num_of_points_considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_anomaly_score = []\n",
    "val = int(0.2 * len(data))\n",
    "new_anomaly_score = anomaly_score[val:]\n",
    "print(len(new_anomaly_score))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(data, c='red', label='Original')\n",
    "plt.xlabel('X-Coordinates')\n",
    "plt.ylabel('Y-Coordinates')\n",
    "plt.title('Visualization')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(new_anomaly_score, c='blue', label='Anomaly Score')\n",
    "plt.xlabel('X-Coordinates')\n",
    "plt.ylabel('Y-Coordinates')\n",
    "plt.title('Visualization')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
